
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Welcome to PFG’s documentation! &#8212; PFG  documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/alabaster.css" />
    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/sphinx_highlight.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="API at a glance" href="api.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="section" id="welcome-to-pfg-s-documentation">
<h1>Welcome to PFG’s documentation!<a class="headerlink" href="#welcome-to-pfg-s-documentation" title="Permalink to this heading">¶</a></h1>
<div class="toctree-wrapper compound">
</div>
<div class="section" id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this heading">¶</a></h2>
<p>Preconditioned functional gradient flow (PFG) is a particle-based sampling framework, which aims to minimize the KL divergence between particle samples and the target distribution with the gradient flow estimates within a parametric function class.</p>
</div>
<div class="section" id="installation">
<h2>Installation<a class="headerlink" href="#installation" title="Permalink to this heading">¶</a></h2>
<p>Install the requirements with</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="o">-</span><span class="n">r</span> <span class="n">requirements</span><span class="o">.</span><span class="n">txt</span>
</pre></div>
</div>
<p>This package can be be installed from sources with the following command:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="n">setup</span><span class="o">.</span><span class="n">py</span> <span class="n">install</span>
</pre></div>
</div>
</div>
<div class="section" id="description">
<h2>Description<a class="headerlink" href="#description" title="Permalink to this heading">¶</a></h2>
<p>In this work, we mainly have two parts to construct our package: <code class="docutils literal notranslate"><span class="pre">pfg.sampler</span></code> and <code class="docutils literal notranslate"><span class="pre">pfg.tasks</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">pfg.tasks</span></code> defines the unnormalized log posterior density conditioned on a dataset, where the log density can be queried by subsampling (stochastic estimation).</p>
<p><code class="docutils literal notranslate"><span class="pre">pfg.sampler</span></code> contains the particle samplers, including PFG, SVGD, SGLD. Given an unnormalized density, the sampler will produce several sample particles from the corresponding distribution.</p>
</div>
<div class="section" id="usage">
<h2>Usage<a class="headerlink" href="#usage" title="Permalink to this heading">¶</a></h2>
<p>To use our code, we provide a standard procedure to use PFG framework to obtain particle samples</p>
<p><strong>Step 1:</strong>
Import data <code class="docutils literal notranslate"><span class="pre">X_train</span></code> and <code class="docutils literal notranslate"><span class="pre">y_train</span></code>;</p>
<p><strong>Step 2:</strong>
Construct a model by feeding data to a task, e.g. Bayesian Neural Networks.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">pfg</span><span class="o">.</span><span class="n">tasks</span><span class="o">.</span><span class="n">BayesianNN</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span>
                                 <span class="n">num_particles</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Step 3:</strong>
Initialize a sampler trainer.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Initialize particles</span>
<span class="n">theta</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>

<span class="c1"># For PFG, we have to define the function class first</span>
<span class="n">activation</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_features</span><span class="p">,</span> <span class="n">h</span><span class="p">),</span>
                     <span class="n">activation</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">h</span><span class="p">),</span>
                     <span class="n">activation</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">n_features</span><span class="p">))</span>

<span class="c1"># Define trainer</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">sampler</span><span class="o">.</span><span class="n">PFG</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">net</span><span class="p">,</span> <span class="n">optim</span> <span class="o">=</span> <span class="n">opt</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Step 4:</strong>
Train a sampler.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ITERATION</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
   <span class="n">trainer</span><span class="o">.</span><span class="n">compute_grad</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
   <span class="n">trainer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</pre></div>
</div>
<p><strong>Step 5:</strong>
Return particles <code class="docutils literal notranslate"><span class="pre">theta</span></code>.</p>
</div>
<div class="section" id="examples">
<h2>Examples<a class="headerlink" href="#examples" title="Permalink to this heading">¶</a></h2>
<p>We provide several examples to show how to use our package in your problem.</p>
<p>You may refer to <code class="docutils literal notranslate"><span class="pre">examples/</span></code> for more details.</p>
</div>
<div class="section" id="api">
<h2>API<a class="headerlink" href="#api" title="Permalink to this heading">¶</a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="api.html">API at a glance</a></li>
</ul>
</div>
</div>
<div class="section" id="citing">
<h2>Citing<a class="headerlink" href="#citing" title="Permalink to this heading">¶</a></h2>
<p>If this software is useful for you, please consider citing
<a class="reference external" href="https://arxiv.org/abs/2211.13954">our paper</a> that describes
the PFG framework:</p>
<div class="highlight-bibtex notranslate"><div class="highlight"><pre><span></span><span class="nc">@inproceedings</span><span class="p">{</span><span class="w"></span>
<span class="w">   </span><span class="nl">dong2023particlebased</span><span class="p">,</span><span class="w"></span>
<span class="w">   </span><span class="na">title</span><span class="p">=</span><span class="s">{Particle-based Variational Inference with Preconditioned Functional Gradient Flow}</span><span class="p">,</span><span class="w"></span>
<span class="w">   </span><span class="na">author</span><span class="p">=</span><span class="s">{Hanze Dong and Xi Wang and Yong Lin and Tong Zhang}</span><span class="p">,</span><span class="w"></span>
<span class="w">   </span><span class="na">booktitle</span><span class="p">=</span><span class="s">{International Conference on Learning Representations}</span><span class="p">,</span><span class="w"></span>
<span class="w">   </span><span class="na">year</span><span class="p">=</span><span class="s">{2023}</span><span class="p">,</span><span class="w"></span>
<span class="w">   </span><span class="na">url</span><span class="p">=</span><span class="s">{https://openreview.net/forum?id=6OphWWAE3cS}</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</pre></div>
</div>
</div>
<div class="section" id="support">
<h2>Support<a class="headerlink" href="#support" title="Permalink to this heading">¶</a></h2>
<p>If you are having issues, please let us know and send email to hdongaj AT ust.hk.</p>
</div>
<div class="section" id="indices-and-tables">
<h2>Indices and tables<a class="headerlink" href="#indices-and-tables" title="Permalink to this heading">¶</a></h2>
<ul class="simple">
<li><p><a class="reference internal" href="genindex.html"><span class="std std-ref">Index</span></a></p></li>
<li><p><a class="reference internal" href="search.html"><span class="std std-ref">Search Page</span></a></p></li>
</ul>
</div>
</div>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="#">PFG</a></h1>








<h3>Navigation</h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="api.html">API at a glance</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="#">Documentation overview</a><ul>
      <li>Next: <a href="api.html" title="next chapter">API at a glance</a></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2022, Hanze Dong.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 5.2.3</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="_sources/index.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>